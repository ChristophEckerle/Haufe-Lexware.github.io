---
layout: post
title: Traefik
subtitle: Web server fitting nicely with docker
category: dev
tags: [traefik, docker, devops, development]
author: Christoph Eckerle, Philipp HÃ¶flin, Drilon Konjufka, Rainer Michel
author_email: rainer.michel@haufe-lexeware.com
header-img: "images/new/Exportiert_45.jpg"
---



1. Table of Contents
{:toc}

## Introduction

You may have made this experience already, you like to implement a solution which is supported by an external tool and at the first look it seems easy. 
As more and more you have to adopt the tool to your use case, the wheat is separated from the chaff: Some tools occasion high adoption costs, some are indeed easy to use and others make just fun to work with. 
In this blog post we talk about our experience by implementing the open source http proxy 'Traefik' - in advance, it is fun to work with! 

Now you may ask, why is it fun to work with Traefik? From our point of view Traefik fits nicely in dockerized environments, because it runs natively on Docker. It is easy to expose any http service and
you can add basic auth and handle SSL in a comfortable way because it is centralized. Furthermore due to hot swapping you need no down times for configuration changes. 
Especially the last point is an advantage compared to e.g. Nginx and therefore Traefik fits to dynamic and service orientated environments. 

By reading this article you will getting to know the basic concepts of Traefik. You will getting an expression how to setup a network to bridge between docker containers and frontends in a docker-swarm-cluster. 
Additionally you will get hints how you can secure your environment, configure Traefik for hot swapping and load balancing within the use case of Traefik as a gateway for data pipelines. 
At the end of the blog post we reflect our recognized down sides of Traefik. 


## Basics

### Source and Features
Traefik is a natively dockerized reverse proxy and load balancer to shield backend services from frontends by act as a single entry point. You can get Traefik from [github](https://github.com/containous/traefik).
It is written in go and deployed as a single binary. Traefik supports circuit breakers, round robin patterns, websocket and http/2, access logs e.g. in JSON-format, integration to metric-apps like Prometheus and the open certificate authority 'let`s encrypt'.
Traefik owns an AngularJS [Web UI](https://github.com/containous/traefik#web-ui) to check the health state, http errors and routing rule sets during runtime. Current natively supported backends are Swarm, Kuberenetes, Mesos, Consul and AWS ECS, to name a few popular samples.
Additionally there is a general REST Api.

### Central Concepts
You can get the Traefik binary via github and start the Docker image via docker run. In the next step you configure Traefik by editing a docker-compose.yml, which you will see in the following chapters how to do in more detail. 
But before we talk about how we use Traefik for our specific use cases, we like to explain the central concepts of Traefik which are listed below:

- **Entrypoints** are the network entrypoints for Traefik by using a port, SSL certificates, keys or redirections to other http/s entrypoints. Following sample shows a https entrypoint exposed on port 443
  and and additional tls configuration with linked certifcate- and key-files:  
  ```yml
        [entryPoints]
            [entryPoints.https]
              address = ":443"
            [entryPoints.https.tls]
              [[entryPoints.https.tls.certificates]]
               certFile = "tests/traefik.crt"
               keyFile = "tests/traefik.key"
  ...
  ```

- **Frontends** are rule sets which define how to handle incoming requests from the entrypoint. The rule sets by itself are clustered by Modifiers and Matchers. 
  Modifiers are only modify the request, e.g. by adding a path prefix. Matchers checking defined patterns to forward to a backend, e.g by http headers.
  ```yml
       [frontends.frontend1.routes.test_1]
             rule = "Host:test1.localhost;Path:/test"
        [frontends.frontend2.headers.customresponseheaders]
           X-Custom-Response-Header = "True"
  ...
  ```         
     
- **Backends** are responsible to load-balance the forwarded traffic from frontends by defined rule sets, e.g. via max connection limit. In this sample the 16th request will get a 429 'too many requests' from Traefik.
    ```yml
        [backends]
          [backends.backend1]
            [backends.backend1.maxconn]
               amount = 15
               client.ip = "request.host"
     ...
     ```   
     
Behind these three main concepts are further sub-concepts. We like to point out one more concept so you understand the use cases in the next chapters. Let`s talk about 'labels':

- **Labels** in the Traefik context are linked to Docker labels. With labels you can add metadata to docker objects like containers or services etc. Thanks to these labels we can configure Traefik to create internal
routing rule sets. In the sample below we use container and service labels to define an app service which is listing on port 9000. 

  ```yml
        - "traefik.backend="my-coolest-app"
        - "traefik.docker.network=web"
        - "traefik.frontend.rule=Host:app.my-coolest-app.io"
        - "traefik.enable=true"
        - "traefik.port=9000"
   ...
  ```   
     
     
     
To get hands-on with the Traefik basics you can find tutorials on [katacoda.com](https://www.katacoda.com/courses/traefik/deploy-load-balancer)

  
  
## Traefik for a multi-dev environment

### Use Case

We want to run several instances of an application and an ActiveMQ broker on a single virtual machine. Each application instance consists of a Tomcat server (Tomcat) and a database (MySQL). We want to assign different (sub-) domain names to the application server instances and to the web UI of ActiveMQ. Without Traefik we have to address the following problems:

* The application servers need different ports. The standard port :443 can only be used for one instance.
* A solution to map the different domain names is needed, e.g. configuring a DNS server.
* A web server needs to be installed to handle TLS as we do not want this handled by Tomcat

We found that these use cases could be addressed easily using Traefik.

![Overview of Development Environment]({{ site.baseurl }}/images/traefik/20180220-Traefik-logisch.png "Fig. 1: Overview of Development Environment")


### General Network Setup

The application instances are set up as docker containers that communicate over a default bridge network. You can find those networks as 10.01.0/24 and 10.0.2.0/24 depicted below. They allow communication between the Tomcat and the MySQL servers.

Both Tomcats provide their default port :8080 for HTTP(S) communication. Instead of exposing those ports directly we create a separate overlay network (10.0.0.0/24). Traefik uses this network to manage the traffic to the application servers. The same holds for ActiveMQ and its web UI that is provided on port :8161.

Traefik can be configured to provide access to all HTTP(S) endpoints through port :443 as a central access point for all clients and manage virtual hosts. The application servers become virtual hosts. Traefik routes HTTP requests to jms.mydomain.com:443 to activemq running on 10.0.0.64:8161 and those to 01-app.mydomain.com:443 to 10.0.0.46:8080 and so forth.

As you can expect from a web server acting as a web proxy, Traefik can terminate the TLS connection and pass the requests as HTTP requests to the application servers.

![Network Layout]({{ site.baseurl }}/images/traefik/20180220-Traefik-Network.png "Fig. 2: Network Layout")


### Configuration

We use docker swarm to set up the docker services. Traefik is configured by the following docker-compose file:
```yml
version: '3.4'

services:
  traefik:
    command: >
      --docker
      --docker.watch
      --docker.swarmmode
      --docker.domain=mydomain.com
      --docker.exposedbydefault=false
      --docker.trace
    networks:
      - frontend
    ports:
      - "443:443"
...
```

This section advices Traefik to manage access to the services running in network `frontend`.

This network has been set up as an overlay network:
```sh
docker network create --driver overlay traefik_ingress
```

We introduce a reference to this network as frontend in the docker-compose file for Traefik (and the services respectively):

```yml
networks:
  frontend:
    external:
      name: traefik_ingress
```

Traefik will automatically manage new services that connect to the frontend network. The sample docker-compose for the application server illustrates this:

```yml
services:
  app:
    networks:
      - frontend
      - backend
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.port=8080"
        - "traefik.docker.network=traefik_ingress"
        - "traefik.frontend.rule=Host: 01-app.mydomain.com"
```

We connect the application server to two networks: frontend and backend. Whereas backend is the bridge network automatically set up, frontend is again our overlay network `traefik_ingress`. We connect the application service `app` to Traefik using service labels:

traefik.enable | tell Traefik to manage access to this service
traefik.port   | the service is available on port 8080
traefik.docker.network | the managed network
traefik.frontend.rule  | the virtual host. All requests to this host are directed to the given service.  

And as a second example the docker-compose file for ActiveMQ:

```yml
services:
  activemq:
    networks:
      - frontend
    deploy:
      labels:
        - "traefik.enable=true"
        - "traefik.port=8161"
        - "traefik.docker.network=traefik_ingress"
        - "traefik.frontend.rule=Host: jms.mydomain.com"

```


## Traefik as a gataway for data integration pipelines


For data integration of various systems we create data pipelines based on Apache Camel and Spring Boot and deploy as Docker containers. Apache Camel is an open source integration framework based on the concepts of Enterprise Integration Patterns. These are Java applications which hold the processing logic and make sure the data is transformed and transferred to the desired destinations.

In the past, each data pipeline service was deployed in a different port. We started to be in the situtation where there is a high number of data pipelines, growing with time and becoming difficult to manage.
We wanted something that would allow faster development of applications and to shield the underlying data pipelines. Moreover not to publish applications in different ports anymore but to use a gateway concept and use APIs something like:                   
`htpps://server/application/endpoint`

![Container Layout]({{ site.baseurl }}/images/traefik/20180220-Traefik-Data-Pipelines.png "Fig. 3: Container Layout")

### Security
Traefik was a good choice to use as a gateway to shield the underlying data pipelines and handling the HTTPS termination. Now the data pipelines have only the necessary code to function, and the routing and security logic is in Traefik.
Currently only the port for HTTPS is opened for Traefik and the containers are not published through ports. The only way to access a container is through the gateway.

### Configuration hot swapping
As a first choice for a gateway was Nginx. It has very good routing possibilities and it is quite known and well documented. By deploying a new container, the Nginx configuration needed to be modified to route to the newly added container. The data pipelines are services which retrieve and transfer millions of records per hour and they would need to be forcedly stopped until the Nginx container is restarted with the new configuration.
It has always intrigued me the concept of hot-swapping of server hard drives. You can just repace one while the system is running, after some time it will re-balance all the information without stopping the server. In software this should have been easier.
Using Traefik these issues are solved. The new container is deployed in the server and it is automatically discovered and the messages would be routed accordingly from outside to the container.
As a good alternative would be also Netflix Zuul in combination with Eureka, but with a bigger memory footprint and without a UI.

### Load Balancing
For data pipelines the concept of load balancing if more difficult because the data is usually handled in a bulk manner and not in per row basis. For the web application in the other hand is very easily to manage the load balancing in Trafeik. The default one was round robin, where the messages get forwarded in a cycle. If one of the containers stops, the requests will still be forwarded to the remaining ones.

### Caveats
Of course Traefik also has some caveats. It was build as simple as possible and does not have some of the features we want.
Three importat not supported features would be:
* Support for JWT (JSON Web Tokens)
* Not handling the security header `x-api-key` differently
* Supporting only HTTP and not generic TCP routing

Currently you need to implement the JWT logic in each application or have a JWT service that would validate the tokens. Some non official github branches have already implemented this and some are building the application from source and adding this functionality.
The security header `x-api-key` is used usually for passing a secret key. In the admin UI this key is visible and can be viewed only by the administrator, still it is a security issue.
For simple services that requires only one api-key we are using Trafeik. Handling multiple api-keyes is more difficult and probably is not meant to be used as an API gateway.
Since the routing is done based in HTTP headers, forwarding TCP trafic is not supported. We deploy also databases in Docker and they cannot be handeled with Traefik and the only way is still to use a dedicated port.
